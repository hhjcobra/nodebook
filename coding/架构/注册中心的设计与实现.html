
    <html lang="en" class="simpread-font simpread-theme-root" style="false">
    <head>
        <meta charset="UTF-8">
        <meta name="author" content="Kenshin"/>
        <meta name="description" content="简悦 ( SimpRead ) - 让你瞬间进入沉浸式阅读的 Chrome extension" />
        <meta name="keywords" content="Chrome extension, Chrome 扩展, 阅读模式, 沉浸式阅读, read mode, reading mode, reader view"/>
        <meta name="thumbnail" content="https://simpread-1254315611.cos.ap-shanghai.myqcloud.com/static/introduce-2.png"/>

        <link rel="stylesheet" href="http://sr.ksria.cn/puread/simpread.css"                  type="text/css" media="all">
        <link rel="stylesheet" href="http://sr.ksria.cn/puread/theme_common.css"              type="text/css" media="all">
        <link rel="stylesheet" href="http://sr.ksria.cn/puread/theme_github.css" type="text/css" media="all">

        <style type="text/css" id="simpread-custom-art">sr-rd-content *, sr-rd-content p, sr-rd-content div {}</style><style type="text/css" id="simpread-custom-code">sr-rd-content pre code, sr-rd-content pre code * {}</style><style type="text/css" id="simpread-custom-desc">sr-rd-desc {}</style><style type="text/css" id="simpread-custom-pre">sr-rd-content pre {}</style><style type="text/css" id="simpread-custom-title">sr-rd-title {}</style><style type="text/css" id="simpread-custom-css"></style><style type="text/css" id="simpread-custom-art">sr-rd-content *, sr-rd-content p, sr-rd-content div {}</style><style type="text/css" id="simpread-custom-code">sr-rd-content pre code, sr-rd-content pre code * {}</style><style type="text/css" id="simpread-custom-desc">sr-rd-desc {}</style><style type="text/css" id="simpread-custom-pre">sr-rd-content pre {}</style><style type="text/css" id="simpread-custom-title">sr-rd-title {}</style><style type="text/css" id="simpread-custom-css"></style><style type="text/css" id="simpread-custom-art">sr-rd-content *, sr-rd-content p, sr-rd-content div {}</style><style type="text/css" id="simpread-custom-code">sr-rd-content pre code, sr-rd-content pre code * {}</style><style type="text/css" id="simpread-custom-desc">sr-rd-desc {}</style><style type="text/css" id="simpread-custom-pre">sr-rd-content pre {}</style><style type="text/css" id="simpread-custom-title">sr-rd-title {}</style><style type="text/css" id="simpread-custom-css"></style><style type="text/css" id="simpread-custom-art">sr-rd-content *, sr-rd-content p, sr-rd-content div {}</style><style type="text/css" id="simpread-custom-code">sr-rd-content pre code, sr-rd-content pre code * {}</style><style type="text/css" id="simpread-custom-desc">sr-rd-desc {}</style><style type="text/css" id="simpread-custom-pre">sr-rd-content pre {}</style><style type="text/css" id="simpread-custom-title">sr-rd-title {}</style><style type="text/css" id="simpread-custom-css"></style><style type="text/css" id="simpread-custom-art">sr-rd-content *, sr-rd-content p, sr-rd-content div {}</style><style type="text/css" id="simpread-custom-code">sr-rd-content pre code, sr-rd-content pre code * {}</style><style type="text/css" id="simpread-custom-desc">sr-rd-desc {}</style><style type="text/css" id="simpread-custom-pre">sr-rd-content pre {}</style><style type="text/css" id="simpread-custom-title">sr-rd-title {}</style><style type="text/css" id="simpread-custom-css"></style><style type="text/css" id="simpread-custom-art">sr-rd-content *, sr-rd-content p, sr-rd-content div {}</style><style type="text/css" id="simpread-custom-code">sr-rd-content pre code, sr-rd-content pre code * {}</style><style type="text/css" id="simpread-custom-desc">sr-rd-desc {}</style><style type="text/css" id="simpread-custom-pre">sr-rd-content pre {}</style><style type="text/css" id="simpread-custom-title">sr-rd-title {}</style><style type="text/css" id="simpread-custom-css"></style><style type="text/css" id="simpread-custom-art">sr-rd-content *, sr-rd-content p, sr-rd-content div {}</style><style type="text/css" id="simpread-custom-code">sr-rd-content pre code, sr-rd-content pre code * {}</style><style type="text/css" id="simpread-custom-desc">sr-rd-desc {}</style><style type="text/css" id="simpread-custom-pre">sr-rd-content pre {}</style><style type="text/css" id="simpread-custom-title">sr-rd-title {}</style><style type="text/css" id="simpread-custom-css"></style><style type="text/css" id="simpread-custom-art">sr-rd-content *, sr-rd-content p, sr-rd-content div {letter-spacing: 1px;}</style><style type="text/css" id="simpread-custom-code">sr-rd-content pre code, sr-rd-content pre code * {}</style><style type="text/css" id="simpread-custom-desc">sr-rd-desc {}</style><style type="text/css" id="simpread-custom-pre">sr-rd-content pre {}</style><style type="text/css" id="simpread-custom-title">sr-rd-title {}</style><style type="text/css" id="simpread-custom-css"></style><style type="text/css" id="simpread-custom-art">sr-rd-content *, sr-rd-content p, sr-rd-content div {}</style><style type="text/css" id="simpread-custom-code">sr-rd-content pre code, sr-rd-content pre code * {}</style><style type="text/css" id="simpread-custom-desc">sr-rd-desc {}</style><style type="text/css" id="simpread-custom-pre">sr-rd-content pre {}</style><style type="text/css" id="simpread-custom-title">sr-rd-title {}</style><style type="text/css" id="simpread-custom-css"></style><style type="text/css" id="simpread-custom-art">sr-rd-content *, sr-rd-content p, sr-rd-content div {}</style><style type="text/css" id="simpread-custom-code">sr-rd-content pre code, sr-rd-content pre code * {}</style><style type="text/css" id="simpread-custom-desc">sr-rd-desc {}</style><style type="text/css" id="simpread-custom-pre">sr-rd-content pre {}</style><style type="text/css" id="simpread-custom-title">sr-rd-title {}</style><style type="text/css" id="simpread-custom-css"></style><style type="text/css" id="simpread-custom-art">sr-rd-content *, sr-rd-content p, sr-rd-content div {}</style><style type="text/css" id="simpread-custom-code">sr-rd-content pre code, sr-rd-content pre code * {}</style><style type="text/css" id="simpread-custom-desc">sr-rd-desc {}</style><style type="text/css" id="simpread-custom-pre">sr-rd-content pre {}</style><style type="text/css" id="simpread-custom-title">sr-rd-title {}</style><style type="text/css" id="simpread-custom-css"></style><style type="text/css" id="simpread-custom-art">sr-rd-content *, sr-rd-content p, sr-rd-content div {}</style><style type="text/css" id="simpread-custom-code">sr-rd-content pre code, sr-rd-content pre code * {}</style><style type="text/css" id="simpread-custom-desc">sr-rd-desc {}</style><style type="text/css" id="simpread-custom-pre">sr-rd-content pre {}</style><style type="text/css" id="simpread-custom-title">sr-rd-title {}</style><style type="text/css" id="simpread-custom-css"></style><style type="text/css" id="simpread-custom-art">sr-rd-content *, sr-rd-content p, sr-rd-content div {}</style><style type="text/css" id="simpread-custom-code">sr-rd-content pre code, sr-rd-content pre code * {}</style><style type="text/css" id="simpread-custom-desc">sr-rd-desc {}</style><style type="text/css" id="simpread-custom-pre">sr-rd-content pre {}</style><style type="text/css" id="simpread-custom-title">sr-rd-title {}</style><style type="text/css" id="simpread-custom-css"></style><style type="text/css" id="simpread-custom-art">sr-rd-content *, sr-rd-content p, sr-rd-content div {}</style><style type="text/css" id="simpread-custom-code">sr-rd-content pre code, sr-rd-content pre code * {}</style><style type="text/css" id="simpread-custom-desc">sr-rd-desc {}</style><style type="text/css" id="simpread-custom-pre">sr-rd-content pre {}</style><style type="text/css" id="simpread-custom-title">sr-rd-title {}</style><style type="text/css" id="simpread-custom-css"></style><style type="text/css" id="simpread-custom-art">sr-rd-content *, sr-rd-content p, sr-rd-content div {text-indent: 2px;}</style><style type="text/css" id="simpread-custom-code">sr-rd-content pre code, sr-rd-content pre code * {}</style><style type="text/css" id="simpread-custom-desc">sr-rd-desc {}</style><style type="text/css" id="simpread-custom-pre">sr-rd-content pre {}</style><style type="text/css" id="simpread-custom-title">sr-rd-title {}</style><style type="text/css" id="simpread-custom-css"></style><style type="text/css" id="simpread-custom-art">sr-rd-content *, sr-rd-content p, sr-rd-content div {}</style><style type="text/css" id="simpread-custom-code">sr-rd-content pre code, sr-rd-content pre code * {}</style><style type="text/css" id="simpread-custom-desc">sr-rd-desc {}</style><style type="text/css" id="simpread-custom-pre">sr-rd-content pre {}</style><style type="text/css" id="simpread-custom-title">sr-rd-title {}</style><style type="text/css" id="simpread-custom-css"></style><style type="text/css" id="simpread-custom-art">sr-rd-content *, sr-rd-content p, sr-rd-content div {}</style><style type="text/css" id="simpread-custom-code">sr-rd-content pre code, sr-rd-content pre code * {}</style><style type="text/css" id="simpread-custom-desc">sr-rd-desc {}</style><style type="text/css" id="simpread-custom-pre">sr-rd-content pre {}</style><style type="text/css" id="simpread-custom-title">sr-rd-title {}</style><style type="text/css" id="simpread-custom-css"></style><style type="text/css" id="simpread-custom-art">sr-rd-content *, sr-rd-content p, sr-rd-content div {}</style><style type="text/css" id="simpread-custom-code">sr-rd-content pre code, sr-rd-content pre code * {}</style><style type="text/css" id="simpread-custom-desc">sr-rd-desc {}</style><style type="text/css" id="simpread-custom-pre">sr-rd-content pre {}</style><style type="text/css" id="simpread-custom-title">sr-rd-title {}</style><style type="text/css" id="simpread-custom-css"></style><style type="text/css" id="simpread-custom-art">sr-rd-content *, sr-rd-content p, sr-rd-content div {}</style><style type="text/css" id="simpread-custom-code">sr-rd-content pre code, sr-rd-content pre code * {}</style><style type="text/css" id="simpread-custom-desc">sr-rd-desc {}</style><style type="text/css" id="simpread-custom-pre">sr-rd-content pre {}</style><style type="text/css" id="simpread-custom-title">sr-rd-title {}</style><style type="text/css" id="simpread-custom-css"></style><style type="text/css" id="simpread-custom-art">sr-rd-content *, sr-rd-content p, sr-rd-content div {}</style><style type="text/css" id="simpread-custom-code">sr-rd-content pre code, sr-rd-content pre code * {}</style><style type="text/css" id="simpread-custom-desc">sr-rd-desc {}</style><style type="text/css" id="simpread-custom-pre">sr-rd-content pre {}</style><style type="text/css" id="simpread-custom-title">sr-rd-title {}</style><style type="text/css" id="simpread-custom-css"></style><style type="text/css" id="simpread-custom-art">sr-rd-content *, sr-rd-content p, sr-rd-content div {}</style><style type="text/css" id="simpread-custom-code">sr-rd-content pre code, sr-rd-content pre code * {}</style><style type="text/css" id="simpread-custom-desc">sr-rd-desc {}</style><style type="text/css" id="simpread-custom-pre">sr-rd-content pre {}</style><style type="text/css" id="simpread-custom-title">sr-rd-title {}</style><style type="text/css" id="simpread-custom-css"></style><style type="text/css" id="simpread-custom-art">sr-rd-content *, sr-rd-content p, sr-rd-content div {}</style><style type="text/css" id="simpread-custom-code">sr-rd-content pre code, sr-rd-content pre code * {}</style><style type="text/css" id="simpread-custom-desc">sr-rd-desc {}</style><style type="text/css" id="simpread-custom-pre">sr-rd-content pre {}</style><style type="text/css" id="simpread-custom-title">sr-rd-title {}</style><style type="text/css" id="simpread-custom-css"></style><style type="text/css" id="simpread-custom-art">sr-rd-content *, sr-rd-content p, sr-rd-content div {}</style><style type="text/css" id="simpread-custom-code">sr-rd-content pre code, sr-rd-content pre code * {}</style><style type="text/css" id="simpread-custom-desc">sr-rd-desc {}</style><style type="text/css" id="simpread-custom-pre">sr-rd-content pre {}</style><style type="text/css" id="simpread-custom-title">sr-rd-title {}</style><style type="text/css" id="simpread-custom-css"></style><style type="text/css" id="simpread-custom-art">sr-rd-content *, sr-rd-content p, sr-rd-content div {}</style><style type="text/css" id="simpread-custom-code">sr-rd-content pre code, sr-rd-content pre code * {}</style><style type="text/css" id="simpread-custom-desc">sr-rd-desc {}</style><style type="text/css" id="simpread-custom-pre">sr-rd-content pre {}</style><style type="text/css" id="simpread-custom-title">sr-rd-title {}</style><style type="text/css" id="simpread-custom-css"></style><style type="text/css" id="simpread-custom-art">sr-rd-content *, sr-rd-content p, sr-rd-content div {}</style><style type="text/css" id="simpread-custom-code">sr-rd-content pre code, sr-rd-content pre code * {}</style><style type="text/css" id="simpread-custom-desc">sr-rd-desc {}</style><style type="text/css" id="simpread-custom-pre">sr-rd-content pre {}</style><style type="text/css" id="simpread-custom-title">sr-rd-title {}</style><style type="text/css" id="simpread-custom-css"></style><style type="text/css" id="simpread-custom-art">sr-rd-content *, sr-rd-content p, sr-rd-content div {}</style><style type="text/css" id="simpread-custom-code">sr-rd-content pre code, sr-rd-content pre code * {}</style><style type="text/css" id="simpread-custom-desc">sr-rd-desc {}</style><style type="text/css" id="simpread-custom-pre">sr-rd-content pre {}</style><style type="text/css" id="simpread-custom-title">sr-rd-title {}</style><style type="text/css" id="simpread-custom-css"></style><style type="text/css" id="simpread-custom-art">sr-rd-content *, sr-rd-content p, sr-rd-content div {letter-spacing: 1px;}</style><style type="text/css" id="simpread-custom-code">sr-rd-content pre code, sr-rd-content pre code * {}</style><style type="text/css" id="simpread-custom-desc">sr-rd-desc {}</style><style type="text/css" id="simpread-custom-pre">sr-rd-content pre {}</style><style type="text/css" id="simpread-custom-title">sr-rd-title {}</style><style type="text/css" id="simpread-custom-css"></style><style type="text/css" id="simpread-custom-art">sr-rd-content *, sr-rd-content p, sr-rd-content div {}</style><style type="text/css" id="simpread-custom-code">sr-rd-content pre code, sr-rd-content pre code * {}</style><style type="text/css" id="simpread-custom-desc">sr-rd-desc {}</style><style type="text/css" id="simpread-custom-pre">sr-rd-content pre {}</style><style type="text/css" id="simpread-custom-title">sr-rd-title {}</style><style type="text/css" id="simpread-custom-css"></style><style type="text/css" id="simpread-custom-art">sr-rd-content *, sr-rd-content p, sr-rd-content div {letter-spacing: 1px;}</style><style type="text/css" id="simpread-custom-code">sr-rd-content pre code, sr-rd-content pre code * {}</style><style type="text/css" id="simpread-custom-desc">sr-rd-desc {}</style><style type="text/css" id="simpread-custom-pre">sr-rd-content pre {}</style><style type="text/css" id="simpread-custom-title">sr-rd-title {}</style><style type="text/css" id="simpread-custom-css"></style><style type="text/css" id="simpread-custom-art">sr-rd-content *, sr-rd-content p, sr-rd-content div {}</style><style type="text/css" id="simpread-custom-code">sr-rd-content pre code, sr-rd-content pre code * {}</style><style type="text/css" id="simpread-custom-desc">sr-rd-desc {}</style><style type="text/css" id="simpread-custom-pre">sr-rd-content pre {}</style><style type="text/css" id="simpread-custom-title">sr-rd-title {}</style><style type="text/css" id="simpread-custom-css"></style><style type="text/css" id="simpread-custom-art">sr-rd-content *, sr-rd-content p, sr-rd-content div {}</style><style type="text/css" id="simpread-custom-code">sr-rd-content pre code, sr-rd-content pre code * {}</style><style type="text/css" id="simpread-custom-desc">sr-rd-desc {}</style><style type="text/css" id="simpread-custom-pre">sr-rd-content pre {}</style><style type="text/css" id="simpread-custom-title">sr-rd-title {}</style><style type="text/css" id="simpread-custom-css"></style><style type="text/css" id="simpread-custom-art">sr-rd-content *, sr-rd-content p, sr-rd-content div {}</style><style type="text/css" id="simpread-custom-code">sr-rd-content pre code, sr-rd-content pre code * {}</style><style type="text/css" id="simpread-custom-desc">sr-rd-desc {}</style><style type="text/css" id="simpread-custom-pre">sr-rd-content pre {}</style><style type="text/css" id="simpread-custom-title">sr-rd-title {}</style><style type="text/css" id="simpread-custom-css"></style>
        <title>简悦 | 注册中心的设计与实现</title>
        
        <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/styles/default.min.css">
        <style>.hljs{background:transparent!important;}</style>
        
    </head>
    <body>
        <sr-read style="0">
            <sr-rd-title>注册中心的设计与实现</sr-rd-title>
            <sr-rd-desc style="display: none;"></sr-rd-desc>
            <sr-rd-content><h2 id="sr-toc-0">问题</h2><p>客户端如何知道某一个服务的可用节点列表?</p><h2 id="sr-toc-1">要求</h2><ul>
<li>每个服务的实例都会在一个特定的地址 (ip:port) 暴露一系列远程接口，比如 HTTP/REST、RPC 等</li>
<li>服务的实例以及其地址会动态变更 (虚拟机或 Docker 容器的 ip 地址都是动态分配的)</li>
</ul><h2 id="sr-toc-2">解决方案</h2><h3 id="sr-toc-3">负载均衡器</h3><p>类似 Nginx 这类负载均衡器貌似可以解决这个问题，但是只支持静态配置，当我们对服务动态扩容、缩容时，需要联系运维进行对应的配置变更，而且如果你的服务运行在 Docker 或 K8S 时，节点的 IP 都是动态分配的，这时再通过 Nginx 去做服务发现会变的非常麻烦。另外引入一个中间层，就引入了一个潜在的故障点，虽然 Nginx 的性能很高，但多经过一层必然会造成一定的性能损耗。</p><div><pre class="hljs nginx"><span class="hljs-section">server</span> {
    <span class="hljs-attribute">location</span> / {
        <span class="hljs-attribute">proxy_pass</span> http://localhost:8080;
    }

    <span class="hljs-attribute">location</span> /images/ {
        <span class="hljs-attribute">root</span> /data;
    }
}</pre></div><h3 id="sr-toc-4">注册中心</h3><p><a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/7877752/54071447-8895c880-42a7-11e9-83bd-a737658b2549.png"><div class="sr-rd-content-center"><img class="sr-rd-content-img" src="https://user-images.githubusercontent.com/7877752/54071447-8895c880-42a7-11e9-83bd-a737658b2549.png" style="zoom: 0.6;"></div></a></p><p>在动态的环境下最好的方式是通过注册中心解决这个问题，实现一个服务注册中心，存储服务实时的地址、元数据、健康状态等信息。注册中心负责处理服务提供者的注册、注销请求，并定时对该服务的实例进行健康检查。客户端通过注册中心暴露的接口查询该服务的可用实例。</p><h2 id="sr-toc-5">设计方案</h2><p>注册中心其实本质上还是一个存储系统，最早可能就是个静态配置文件，随着系统变得越来越复杂，同时加上现在服务大多都是部署在容器之中，节点 IP 的变更都是动态的，导致静态配置文件的形式已经完全不可用了，因此我们就需要节点能够动态的注册、注销。那么注册中心就需要能够存储这个信息，并实时的维护更新。<br>
最简单其实可以存储到 MySQL 中，由一个单机节点负责处理所有的请求，比如注册、注销、健康监测、服务状态变更事件推送等。<br>
但由于单点问题，单机版没有很好的容灾性，那么我们可以缓存来解决，在客户端 SDK 中通过多级缓存机制: 内存 -&gt; 磁盘快照， 解决因注册中心挂掉而不能获取到数据的问题。<br>
但这样的架构还是有问题，虽然客户端已经和注册中心解耦了，但当注册中心挂掉时，新扩容、缩容或者正常上下线的节点，由于注册中心挂掉了，服务的调用者是不能够获取到这个信息的，因此就会获取到过期的数据。我们很容易就想到冗余，多部署几个节点，但不同于业务应用，注册中心本身是有状态的，不能像业务应用一样简单的部署多个节点解决问题，我们还需要数据同步的问题。</p><h3 id="sr-toc-6">数据同步</h3><p>数据同步其实有非常多的方式，我们看一下业界一些开源注册中心的解决方案.</p><h4 id="sr-toc-7">Eureka 1.X</h4><p><a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/7877752/54071449-8d5a7c80-42a7-11e9-8a67-c80793c4c330.png"><div class="sr-rd-content-center"><img class="" src="https://user-images.githubusercontent.com/7877752/54071449-8d5a7c80-42a7-11e9-8a67-c80793c4c330.png"></div></a></p><p>Eureka client 会优先和同一个可用区的 eureka server 通讯，如果由于网络问题、server 挂掉等原因导致通讯异常，那么客户端 fail over 到其他可用区的 eureka server 上重试。<br>
Eureka 的多副本的一致性协议采用类似 “异步多写” 的 AP 协议，Eureka server 会将收到的收到的所有请求都转发给它所知道的所有其他 eureka server(如果转发失败，会在下一次心跳时继续重试)，其他 eureka server 收到请求会，会在本地重放，从而使得不同 eureka server 之间的状态保持一致。从这一点也可以看出来，eureka 是一个 AP 系统，保证最终一致，因为 eureka 所有 server 都能提供服务，并不是一个 leader based 的系统，当客户端从 eureka server 1 获取服务 B 的数据时，可能服务 B 是和 eureka server 2 建立的连接，而此时 server 2 还没有将最新数据同步到 1，因此此时客户端就会获得过期的数据。<br>
看起来一切都很好，但 eureka 这样类似点对点的同步算法， 会有什么问题呢？</p><ul>
<li>采用广播式的复制模型，所有的 server 会将所有的数据、心跳复制给其他所有的 server，实现起来很简单，但却不失为一种不错的方案，但随着服务节点的增多，广播逐渐会成为系统的瓶颈，因为写入是不能横向扩展的，每次写入请求必须转发给其他所有的 server，因此即使你扩容的更多的节点，系统的性能不但不会提升，反而会有很大的下降。<br>
这里再提一下 eureka 的其他一些问题:</li>
<li>客户端会获取全量的服务数据，并且不支持只获取某一个单独的服务信息，导致占用客户端大量的内存，即使你可能只需要其中某一个服务的地址。</li>
<li>只支持定时更新: eureka 的客户端是通过 pull 的方式从 server 获取服务的最新状态，这样会有几个问题:
<ul>
<li>获取有一定的延迟，具体取决于应用的配置。</li>
<li>如果 pull 的间隔配置的很低，会导致产生很多无用的请求，比如某个节点可能一天才发布一次，但客户端可能每秒都会 pull 一次，导致浪费系统的资源。</li>
<li>配置太多。首次注册延迟、缓存定期更新周期、心跳间隔、主动失效检测间隔等等，当然了也可以说是优点。</li>
</ul>
</li>
</ul><sr-blockquote>
<p>当我们扩容一个新的 eureka server 时，服务启动后，会优先从临近的节点中获取全量的服务数据，如果失败了会继续尝试其他所有节点，如果成功了，那么这个节点就可以开始正式对外提供服务。</p>
</sr-blockquote><h4 id="sr-toc-8">Eureka 2.x</h4><p><a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/7877752/54071451-921f3080-42a7-11e9-82c8-9c2ba3abd983.png"><div class="sr-rd-content-center"><img class="" src="https://user-images.githubusercontent.com/7877752/54071451-921f3080-42a7-11e9-82c8-9c2ba3abd983.png"></div></a></p><p>eureka 2.x 主要就是为了解决以上几个问题而诞生的，主要包含以下几点:</p><ul>
<li>支持按需订阅: eureka 客户端支持只订阅自己感兴趣的服务数据，eureka server 将只会推送客户端感兴趣的数据。</li>
<li>数据推送从 pull 改成 push 模式。</li>
<li>优化同步算法。跟 eureka1.x 一样，eureka2.x 也会将数据广播给其他节点，但与其不同的是，2.x 不会将每一个服务实例的心跳也发送给其他节点，这个简单的优化大大减少了系统整体的流量，提升了系统的扩展性。</li>
<li>读写分离。Eureka2.x 将 eureka 集群分为了写集群和读集群，注册中心是一个典型的写少读多的系统，不管是手动扩容还是自动扩容，扩容之前都可以大概预估一下系统当前的压力，并针对性的对写、读集群扩容。</li>
<li>审计日志以及控制台。</li>
</ul><p><a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/7877752/54071457-9f3c1f80-42a7-11e9-969e-4a2178a3f860.png"><div class="sr-rd-content-center"><img class="" src="https://user-images.githubusercontent.com/7877752/54071457-9f3c1f80-42a7-11e9-969e-4a2178a3f860.png"></div></a></p><p>eureka2.x 虽然进行了大量的优化，但其实还是有些问题，写集群仍然存储的是全量的服务数据，如果服务规模非常大的话，仍然造成瓶颈，需要考虑其他一些分片的方案。</p><h4 id="sr-toc-9">Zookeeper</h4><p><a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/7877752/54071459-a400d380-42a7-11e9-90f6-f648167fb2bb.png"><div class="sr-rd-content-center"><img class="" src="https://user-images.githubusercontent.com/7877752/54071459-a400d380-42a7-11e9-90f6-f648167fb2bb.png"></div></a></p><p>Zookeeper 的基于 ZAB 协议，ZAB 是一个类 Paxos 的分布式一致性算法，因此 zk 的复制其实是交由 zab 协议来保证的，当 leader 收到写请求后，会将整个请求消息复制给其他节点，其他节点收到消息后，会交由本机的状态机处理，从而实现数据的复制，</p><p><a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/7877752/54071460-a6fbc400-42a7-11e9-932d-28fd3d7a330b.png"><div class="sr-rd-content-center"><img class="" src="https://user-images.githubusercontent.com/7877752/54071460-a6fbc400-42a7-11e9-932d-28fd3d7a330b.png"></div></a></p><p>很多人都说 ZK 是一个 CP 系统，其实个人觉得单纯的用 CAP 来描述一个分布式系统已经不太准确了，比如 Zookeeper, 默认情况下客户端会连接到不同的节点，<br>
而节点之间的数据和 leader 是不同步的，存在一定的延迟，因此会导致读取到的数据不一致，可能存在一定的延迟，但是可以通 sync 调用，强制同步一把，从而实现更强的一致性。那么 zk 到底是个 AP 系统还是 CP 系统呢?<br>
这里再提一下 zk 的扩展性，zk 基于 ZAB 协议，写入都必须经过 leader，并同步到其他 follower 节点，因此增加更多的写入节点，意味着写入需要同步到更多的节点，从而引起性能下降，由此也可以看出 zk 并不具备横向扩展性，因此如果简单的通过 zk 去做服务发现，随着服务规模的增长，比如会遇到瓶颈。<br>
但我们可以换一种思路，把 zk 当成一个存储，基于一个 CP 系统构建一个 AP 的注册中心，相较于客户端直连 zk 集群，改成 server 与 zk 集群建立连接，当 server 收到客户端的写请求时，转换成 zk 对应的操作，其他 server 节点设置对应的 watch，监听服务状态的变更，从而实现数据的同步，对于其他类似健康监测、服务状态变更事件推送等则由注册中心的 server 完成。<br>
但其实选择 zk 最需要考虑的问题是运维，因为 zk 相对来说是一个非常复杂的系统，你能不能用得好、出了问题能不能 hold 得住，这都是一个疑问，比如 zk 的状态机你真的理解了么？ZAB 协议知道咋回事么？临时节点知道原理么？事件推送、连接管理都有哪些坑？</p><p><a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/7877752/54071463-a9f6b480-42a7-11e9-96f2-3e06d9cfb158.png"><div class="sr-rd-content-center"><img class="" src="https://user-images.githubusercontent.com/7877752/54071463-a9f6b480-42a7-11e9-96f2-3e06d9cfb158.png"></div></a></p><h4 id="sr-toc-10">Alibaba Nacos</h4><p><a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/7877752/54071467-ae22d200-42a7-11e9-9d9c-dbc3d7ee33c4.png"><div class="sr-rd-content-center"><img class="sr-rd-content-img" src="https://user-images.githubusercontent.com/7877752/54071467-ae22d200-42a7-11e9-9d9c-dbc3d7ee33c4.png" style="zoom: 0.6;"></div></a></p><p>Nacos 是阿里巴巴开源的动态服务发现、配置管理和服务管理平台。对于注册中心这块来说，其一致性算法是基于 Raft 实现的，Raft 类似 Paxos，也是一种一致性协议算法，但是相对 Paxos 来说，要容易理解的多。类似上面说的基于 zk 的方案，nacos 也是基于一个 CP 协议打造的一个 AP 系统，客户端本地是支持快照的，即使服务端挂掉，也不影响客户端的使用。</p><h4 id="sr-toc-11">小结</h4><p>可以看出数据同步其实有非常多的解决方案，具体如何选择其实还是要看业务场景、服务规模等，大部分情况下完全没必要自己造轮子，无脑选择 nacos、eureka 就可以了。</p><h3 id="sr-toc-12">CP or AP</h3><p>CAP 理论指出，在分布式存储系统中，不可能同时满足以下三种条件中的两种:</p><ul>
<li><code>一致性</code>: 每个读请求总是能够获取到最新写入的值</li>
<li><code>可用性</code>: 每个请求都能够接受到对应的响应, 但不需要包含最新写入的值，也就是允许读取到过期的数据</li>
<li><code>分区容忍性</code>: 当发生了网络分区时 (节点之间发生了丢包等现象造成不能正常通讯)，那么系统就必须在 C 和 A 之间选择一个</li>
</ul><h5>数据一致性</h5><p>注册中心最核心的功能其实就三个:</p><ul>
<li>对于调用者来说，能够根据服务的 ID 查询到服务的地址、元数据、健康程度等信息</li>
<li>对于服务提供者来说，能够注册、注销自身提供的服务</li>
<li>注册中心能够检测到服务实例的健康程度，并能够通知给客户端</li>
</ul><p>我们设想一下，假如必须要满足一致性的话，那么当发生网络分区时，注册中心集群被一分为二: 多数区、少数区。那么多数区因为大多数节点仍然能够选出 leader，仍然能够正常处理服务实例的注册、注销、健康监测请求，分区内的客户端也能正常的获取到对应的节点。但是在少数区的节点，由于不能够组成大多数节点，因此不能正常的选举出 leader，而由于我们选择了一致性，就不能处理客户端的读写请求，如果我们处理注册、注销请求的话，就必然会造成数据不一致，而如果我们处理读请求的话，那么这个时候读取的其实是过期的数据，也不能满足一致性。</p><p><a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/7877752/54071470-b5e27680-42a7-11e9-91d4-8449ec3d15f3.png"><div class="sr-rd-content-center"><img class="sr-rd-content-img" src="https://user-images.githubusercontent.com/7877752/54071470-b5e27680-42a7-11e9-91d4-8449ec3d15f3.png" style="zoom: 0.6;"></div></a></p><p>比如说典型的 ZK3 地 5 节点部署架构，当发生网络分区时，机房 1 和机房 2 能够正常通讯，但机房 3 和其他两个机房发生了网络分区，由于 zk 的特性，只要大多数节点能够正常通讯，那么就能够保证整个 zk 集群正常正常对外提供服务，但是位于机房 3 的 zk 节点 5 由于不能和其他节点通讯，是不能够对外提供服务的，读写请求都不能够处理，对应于服务发现的场景来说，就是扩容、缩容的节点不能够正常的注册、注销，另外正常的节点心跳检测也会异常。<br>
但我们发现，虽然机房 3 不能和其他两个机房正常通讯，但机房 3 内所有的服务是能够正常通讯的，机房内的服务调用其实是完全正常的，但由于发生了网络分区，我们优先选择了一致性，对应服务发现的场景来说，也就是服务调用者是获取不到服务实例列表的，即使是同机房内能够正常通讯的节点也不行，这样的行为对于业务方来说通常是不可接受的。</p><p>但对于服务发现的场景来说，一致性其实并没有那么重要，当发生网络分区，客户端获取到的是不完整的节点列表，比如说可能不包含部分节点 (因为不能和另一个分区的 leader 节点通讯，新注册上来的节点也就获取不到)，另外也可能包含其实已经下线的节点 (因为发生了网络分区，心跳监测也会发生异常), 但这个其实问题不大，客户端可以监测对应的异常，对于幂等的读取请求可以 failover 到其他节点上重试，对于写请求，需要对应的服务提供者处理好去重，保证幂等，客户端可以根据自己的业务场景决定具体的策略。但如果选择了一致性，客户端从注册中心获取不到节点，服务整体是不可用的。</p><h5>可用性</h5><p>对于服务发现的场景来说，其实大部分业务方的需求其实一个 AP 系统，也就是发生网络分区时，优先选择可用性，一段时间内的数据不一致其实完全在可接受的范围之内。<br>
比如上面说的场景，当发生网络分区时，机房 3 的 zk 节点不能和其他机房的 leader 节点通讯，但如果我选择了 A， 那么也就是说注册中心可以返回给客户端过期的数据，比如客户端 A 获取服务 B 的节点列表，注册中心可能返回了 10 个节点，但这个 10 个节点中可能就有一些节点已经下线了，因为不能够此时注册中心不能处理写请求，如果能够处理写请求的话，情况会更复杂一些，等网络分区恢复之后，我们还需要处理数据冲突的问题，另外这个 10 个节点的数据可能也不全，可能没有包含新扩容的节点 (比如机房 2 扩容了 5 个节点，并注册到了机房 1 或者 2 的 leader，但 zk5 以为不能和 leader 正常通讯，是获取不到这个数据的)。</p><h3 id="sr-toc-13">健康检查</h3><p>在微服务式的架构之下，每一个服务都会依赖大量其他的服务实例，当其中任何一个实例出现了故障时，系统必须能够在一定是时间内监测到异常，并通知给对应的调用方。大部分系统都是通过心跳机制去监测服务的健康程度。<br>
健康检查大致分为两类:</p><h5>liveness check</h5><p>Liveness 检查主要是用来监测服务的存活状态，例如进程是否还在、端口是否能够 Ping 通等，如果系统挂掉，那么这个时候监测不到进程 id，注册中心会将对应的节点标为异常，并通知对应的节点。</p><h5>readiness check</h5><p>Readiness 检查的作用通常是用来监测服务是否能够对外提供服务，比如说即使能够监测到应用的进程 id，但可能应用还在启动中、缓存还没有预热、代码还没经过 jit 预热等。</p><p><a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/7877752/54071505-428d3480-42a8-11e9-98cf-2976f0b6e31d.png"><div class="sr-rd-content-center"><img class="" src="https://user-images.githubusercontent.com/7877752/54071505-428d3480-42a8-11e9-98cf-2976f0b6e31d.png"></div></a></p><h4 id="sr-toc-14">探针类型</h4><p>一般来说探针大致分为两种:</p><h5>TCP</h5><p><a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/7877752/54071507-46b95200-42a8-11e9-8810-c77ce8018df0.png"><div class="sr-rd-content-center-small"><img class="" src="https://user-images.githubusercontent.com/7877752/54071507-46b95200-42a8-11e9-8810-c77ce8018df0.png"></div></a></p><p>注册中心会定时尝试和对应的 ip:port 建立 tcp 连接，如果能够正常建立连接，则表明服务当前处于健康状态，否则则为异常。</p><h5>HTTP</h5><p><a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/7877752/54071509-4a4cd900-42a8-11e9-9ef2-0fe1f63e06f0.png"><div class="sr-rd-content-center"><img class="" src="https://user-images.githubusercontent.com/7877752/54071509-4a4cd900-42a8-11e9-9ef2-0fe1f63e06f0.png"></div></a></p><p>注册中心会定时调用对应的接口，如果状态码、header 或者响应满足对应的要求，那么则认为该服务当前健康，我们可以在这个接口中针对自己的业务场景检测对应的组件，比如数据库连接是否已经建立、线程池是不是已经被打满了等。</p><h5>其他</h5><p>其他还有一些比如说针对数据库，可以通过发送一个 sql，校验数据库是否能在一定的时间内返回结果，从而监测数据库的健康状况。</p><h5>探针执行策略</h5><p>当然这里还有一些其他的策略，比如超时时间、调用间隔、几次检测失败才将服务视为异常等。这方面可以参考一下 Nginx:</p><div><pre class="hljs nginx"><span class="hljs-attribute">upstream</span> backend {
    <span class="hljs-attribute">server</span> backend1.example.com;
    <span class="hljs-attribute">server</span> backend2.example.com max_fails=<span class="hljs-number">3</span> fail_timeout=<span class="hljs-number">30s</span>;
}</pre></div><h3 id="sr-toc-15">Service Mesh</h3><p><a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/7877752/54071511-4e78f680-42a8-11e9-9ab4-ba4765d1d0c9.png"><div class="sr-rd-content-center"><img class="" src="https://user-images.githubusercontent.com/7877752/54071511-4e78f680-42a8-11e9-9ab4-ba4765d1d0c9.png"></div></a></p><p>蹭下热点简单说一下 Service Mesh,service mesh 的要解决的一个很重要的痛点就是多语言的问题，用 java 的做微服务一般来说直接用 Spring Cloud 这一套就可以了，限流、熔断、服务发现、负载均衡等都有对应的组件支持，如果团队中技术栈是统一的，倒是没什么问题，但是在微服务的架构下，每个团队负责维护自身的服务，这个时候你并不能确保所有的服务都是用同一个语言实现的，但限流、熔断、服务发现等特性是每个微服务都需要的特性，这个时候你就需要将 eureka、Hystrix 用各个不同的语言实现一次，这是一件非常复杂、繁琐且有挑战的事情，很难保证你的代码没有 bug。因此就出现了 Service Mesh, 将一个 agent/sidecar 和服务部署在同一个节点，并接管服务的流量，并能够分析流量，从而得知其协议、要调用的服务等信息，并针对该服务进行服务发现、限流等措施。<br>
那么在多语言的情况下如何去做服务发现呢？给每个语言开发一个单独的 SDK? 也是一种可行的方案，但正如上文所说，非常复杂，而且工作量很大。</p><h4 id="sr-toc-16">DNS</h4><p>DNS 可以说是目前应用最广泛、最通用、支持最广泛的寻址方式。所有的编程语言、平台都支持。因此使用 DNS 作为服务发现的方案是一个非常好的思路，这也正是 K8S 和 Service Mesh(<code>Istio</code>) 的寻址方案。</p><h6>K8S 基于 DNS 的寻址方案</h6><p><a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/7877752/54071515-52a51400-42a8-11e9-8f4d-135cdffc2c44.png"><div class="sr-rd-content-center"><img class="sr-rd-content-img" src="https://user-images.githubusercontent.com/7877752/54071515-52a51400-42a8-11e9-8f4d-135cdffc2c44.png" style="zoom: 0.6;"></div></a></p><p>K8S 的基础概念这里不再累述，如图所示，我们在 k8s 集群中部署一个 uservice，并指定 3 个 pod(实例 / 节点)，应用部署之后，k8s 会给应用分配 ClusterIP 和域名，并生成一条对应的 DNS 记录，将域名映射到 ClusterIP。</p><ul>
<li>当我们调用<code>http://userservice/id/1000221</code>时，k8s 首先会进行域名解析，将 useservice 解析后得到该服务对应的 ClusterIP。</li>
<li>客户端向 ClusterIP 发起请求 ，kube-proxy 拦截到请求报文，得到后端 pod 的 IP 地址列表，并根据一定的负载均衡策略，选择一个 pod 进行请求的处理。</li>
</ul><h6>Service Mesh Istio 基于 DNS 寻址方案</h6><p><a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/7877752/54071517-55a00480-42a8-11e9-8961-bb774a47db2f.png"><div class="sr-rd-content-center"><img class="sr-rd-content-img" src="https://user-images.githubusercontent.com/7877752/54071517-55a00480-42a8-11e9-8961-bb774a47db2f.png" style="zoom: 0.6;"></div></a></p><p>Istio 的方案其实和 K8S 几乎是一样的，只不过说 service mesh 会部署一个 sidecar，而 sidecar 会接管应用所有的流入、流出流量，因此中间会过两层 sidecar(客户端、服务器端都会部署一个 sidecar)。如图所示，除了红色部分外其他步骤都是一致的。</p><h6>Alibaba Nacos DNS-F</h6><p><a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/7877752/54071519-5a64b880-42a8-11e9-8f9d-884b28fc7100.png"><div class="sr-rd-content-center"><img class="" src="https://user-images.githubusercontent.com/7877752/54071519-5a64b880-42a8-11e9-8f9d-884b28fc7100.png"></div></a></p><p>Nacos 也支持通过 dns 进行服务发现，dns-f 客户端和应用部署在同一节点，并拦截应用的 dns 查询请求:</p><ul>
<li>首先，应用 ServiceA 直接通过域名调用 ServiceB 的接口</li>
<li>DNS-F 会拦截到 ServiceA 的请求，通过注册中心查询，是否拥有该服务的注册信息，<br>
若有则根据一定的复杂均衡策略，返回 ip</li>
<li>如果没有查询到，则交给底层的操作系统处理</li>
</ul><h6>小结</h6><p>如果继续 DNS 做服务发现，那么应用就不再需要关心注册中心等细节，对调用方来说就和普通的 HTTP 调用一样，传入一个域名，具体的域名解析交给底层的基础设施，比如 K8S、Istio 等，这样的话比如 Dubbo、配置中心等应用，甚至是数据库的地址，都只需要配置成一个域名，这样的话 Dubbo 就不再需要配置中心了，只要传入一个服务的表示<code>com.xxxxx.UserService:version</code>, k8s/istio 会解析出最终的地址，并且能够针对应用的流量，做限流、重试、监控等，应用能够专注于业务逻辑，这些事情都不需要关心，也不用耦合在代码里，都交给底层基础设施统一管控、升级等。</p><h2 id="sr-toc-17">总结</h2><p>本文大概讲了一下注册中心的设计，其中还有非常多的组件、细节没有涉及到，比如多数据中心、服务事件通知风暴等等问题，后面有时间会继续补充。</p><h2 id="sr-toc-18">参考资料</h2><ul>
<li><a href="https://skyao.io/post/" rel="nofollow">https://skyao.io/post/</a></li>
<li><a href="https://nacos.io/en-us/blog/alibaba-configserver.html" rel="nofollow">https://nacos.io/en-us/blog/alibaba-configserver.html</a></li>
<li><a href="https://medium.com/knerd/eureka-why-you-shouldnt-use-zookeeper-for-service-discovery-4932c5c7e764" rel="nofollow">https://medium.com/knerd/eureka-why-you-shouldnt-use-zookeeper-for-service-discovery-4932c5c7e764</a></li>
<li><a href="http://jm.taobao.org/2018/06/13/%E5%81%9A%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0%EF%BC%9F/" rel="nofollow">http://jm.taobao.org/2018/06/13/%E5%81%9A%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0%EF%BC%9F/</a></li>
<li><a href="https://github.com/Netflix/eureka/wiki/Eureka-2.0-Architecture-Overview">https://github.com/Netflix/eureka/wiki/Eureka-2.0-Architecture-Overview</a></li>
</ul></sr-rd-content>
            <sr-rd-footer>
                <sr-rd-footer-group>
                    <sr-rd-footer-line></sr-rd-footer-line>
                    <sr-rd-footer-text>全文完</sr-rd-footer-text>
                    <sr-rd-footer-line></sr-rd-footer-line>
                </sr-rd-footer-group>
                <sr-rd-footer-copywrite>
                    <div>本文由 <a href="http://ksria.com/simpread" target="_blank">简悦 SimpRead</a> 转码，用以提升阅读体验，<a href="https://github.com/aCoder2013/blog/issues/32" target="_blank">原文地址 </a></div>
                </sr-rd-footer-copywrite>
            </sr-rd-footer>
        </sr-read>
    </body>
    </html>
